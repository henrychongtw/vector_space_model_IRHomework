{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['40889 44022 10092 2471 9800 9561 38208 32528 3015 16920 16271 \\n10528 28193 16868 2572 11437 \\n33886 \\n38208 1200 \\n38208 13812 17231 3153 2710 2903 3015 16920 \\n40889 16972 2718 44022 43444 38478 2913 508 2718 32035 46265 \\n744 3455 9800 38208 1838 1944 2718 612 32528 3015 16920 9561 3025 13674 36506 21387 \\n28516 13247 40889 713 16920 26416 16868 3015 25634 \\n38208 1838 3429 1715 8775 32528 30081 709 21387 3015 16920 \\n24435 596 40889 13703 25312 18366 3015 13894 1330 18318 3082 596 30267 3015 24041 \\n3043 1259 40889 40526 35251 1200 \\n9561 38208 32528 16920 3015 16276 \\n44870 29696 38208 18412 24040 3015 30165 \\n33886 \\n38208 1200 \\n38208 3015 25958 17428 13812 596 1944 2718 612 1730 17231 3153 28654 1190 16970 21387 3015 16920 \\n']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "file_list = glob.glob(os.path.join(os.getcwd(), \"Document\", \"*\"))\n",
    "\n",
    "corpusss = []\n",
    "\n",
    "for file_path in file_list[0:1]:\n",
    "    with open(file_path) as f_input:\n",
    "        next(f_input)\n",
    "        next(f_input)\n",
    "        next(f_input)\n",
    "        lines = f_input.read()\n",
    "        lines = re.sub('-1', '', lines)\n",
    "        corpusss.append(lines)\n",
    "\n",
    "print(corpusss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-9b50b81688a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for doc in corpus:\n",
    "    tf2 = Counter()\n",
    "    for word in doc.split():\n",
    "        tf2[word] += 1\n",
    "    print(tf2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('40889', 5), ('44022', 2), ('10092', 1), ('2471', 1), ('9800', 2), ('9561', 3), ('38208', 9), ('32528', 4), ('3015', 11), ('16920', 7), ('16271', 1), ('10528', 1), ('28193', 1), ('16868', 2), ('2572', 1), ('11437', 1), ('33886', 2), ('1200', 3), ('13812', 2), ('17231', 2), ('3153', 2), ('2710', 1), ('2903', 1), ('16972', 1), ('2718', 4), ('43444', 1), ('38478', 1), ('2913', 1), ('508', 1), ('32035', 1), ('46265', 1), ('744', 1), ('3455', 1), ('1838', 2), ('1944', 2), ('612', 2), ('3025', 1), ('13674', 1), ('36506', 1), ('21387', 3), ('28516', 1), ('13247', 1), ('713', 1), ('26416', 1), ('25634', 1), ('3429', 1), ('1715', 1), ('8775', 1), ('30081', 1), ('709', 1), ('24435', 1), ('596', 3), ('13703', 1), ('25312', 1), ('18366', 1), ('13894', 1), ('1330', 1), ('18318', 1), ('3082', 1), ('30267', 1), ('24041', 1), ('3043', 1), ('1259', 1), ('40526', 1), ('35251', 1), ('16276', 1), ('44870', 1), ('29696', 1), ('18412', 1), ('24040', 1), ('30165', 1), ('25958', 1), ('17428', 1), ('1730', 1), ('28654', 1), ('1190', 1), ('16970', 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "for doc in corpusss:\n",
    "    tf = Counter()\n",
    "    for word in re.split(' |\\\\n', doc):\n",
    "        tf[word] += 1\n",
    "    del tf['']\n",
    "    print(tf.items())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [9800, 38208, 2572, 38478, 13674, 28516, 2710, 21387, 36506, 25312, 28193, 40526, 43444, 24041, 3082, 13894, 44870, 30165, 2903, 2471, 3025, 18366, 744, 18318, 2718, 30267, 1259, 1838, 13247, 16972, 32528, 26416, 2913, 3015, 17231, 30081, 596, 17428, 1715, 713, 508, 16868, 13703, 16970, 33886, 1200, 1944, 35251, 9561, 16920, 32035, 3455, 40889, 3429, 1330, 3043, 29696, 10528, 24435, 16271, 18412, 46265, 612, 16276, 709, 10092, 25958, 24040, 8775, 13812, 28654, 1190, 11437, 3153, 1730, 44022, 25634]\n",
      "The doc is \"40889 44022 10092 2471 9800 9561 38208 32528 3015 16920 16271 \n",
      "10528 28193 16868 2572 11437 \n",
      "33886 \n",
      "38208 1200 \n",
      "38208 13812 17231 3153 2710 2903 3015 16920 \n",
      "40889 16972 2718 44022 43444 38478 2913 508 2718 32035 46265 \n",
      "744 3455 9800 38208 1838 1944 2718 612 32528 3015 16920 9561 3025 13674 36506 21387 \n",
      "28516 13247 40889 713 16920 26416 16868 3015 25634 \n",
      "38208 1838 3429 1715 8775 32528 30081 709 21387 3015 16920 \n",
      "24435 596 40889 13703 25312 18366 3015 13894 1330 18318 3082 596 30267 3015 24041 \n",
      "3043 1259 40889 40526 35251 1200 \n",
      "9561 38208 32528 16920 3015 16276 \n",
      "44870 29696 38208 18412 24040 3015 30165 \n",
      "33886 \n",
      "38208 1200 \n",
      "38208 3015 25958 17428 13812 596 1944 2718 612 1730 17231 3153 28654 1190 16970 21387 3015 16920 \n",
      "\" \n",
      "the tf vector for Document 1 is [2, 9, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 4, 1, 1, 11, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 3, 7, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1]\n",
      "All Combined here is our master document term matrix: \n",
      "[[2, 9, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 4, 1, 1, 11, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 3, 7, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(corpusss)\n",
    "\n",
    "doc_term_matrix = []\n",
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "\n",
    "for doc in corpusss:\n",
    "    print('The doc is \"' + doc + '\" ')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd')for freq in tf_vector)\n",
    "    print('the tf vector for Document %d is [%s]'%((corpusss.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "print('All Combined here is our master document term matrix: ')\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old document term matrix: \n",
      "[[2, 9, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 4, 1, 1, 11, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 3, 7, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1]]\n",
      "1\n",
      "\n",
      " A document term matrix with row-wise L2 norms of 1: \n",
      "[[0.09523809523809523, 0.42857142857142855, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.14285714285714285, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.19047619047619047, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616, 0.047619047619047616, 0.19047619047619047, 0.047619047619047616, 0.047619047619047616, 0.5238095238095238, 0.09523809523809523, 0.047619047619047616, 0.14285714285714285, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.14285714285714285, 0.09523809523809523, 0.047619047619047616, 0.14285714285714285, 0.3333333333333333, 0.047619047619047616, 0.047619047619047616, 0.23809523809523808, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616, 0.047619047619047616, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616, 0.09523809523809523, 0.047619047619047616]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def l2_normalizer(vec):\n",
    "    denom = sum([el**2 for el in vec])\n",
    "    return[(el/math.sqrt(denom)) for el in vec]\n",
    "\n",
    "doc_term_matrix_l2 = []\n",
    "\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "    \n",
    "print('A regular old document term matrix: ')\n",
    "#print(np.matrix(doc_term_matrix))\n",
    "print(doc_term_matrix)\n",
    "print(len(doc_term_matrix))\n",
    "\n",
    "print('\\n A document term matrix with row-wise L2 norms of 1: ')\n",
    "#print(np.matrix(doc_term_matrix_l2))\n",
    "print(doc_term_matrix_l2)\n",
    "print(len(doc_term_matrix_l2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529]\n",
      "77\n",
      "\n",
      "\n",
      "Our vocabulary vector is [9800, 38208, 2572, 38478, 13674, 28516, 2710, 21387, 36506, 25312, 28193, 40526, 43444, 24041, 3082, 13894, 44870, 30165, 2903, 2471, 3025, 18366, 744, 18318, 2718, 30267, 1259, 1838, 13247, 16972, 32528, 26416, 2913, 3015, 17231, 30081, 596, 17428, 1715, 713, 508, 16868, 13703, 16970, 33886, 1200, 1944, 35251, 9561, 16920, 32035, 3455, 40889, 3429, 1330, 3043, 29696, 10528, 24435, 16271, 18412, 46265, 612, 16276, 709, 10092, 25958, 24040, 8775, 13812, 28654, 1190, 11437, 3153, 1730, 44022, 25634]\n",
      "length of vocab\n",
      "77\n",
      "\n",
      "\n",
      "The inverse document frequency vector is [0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147, 0.693147]\n"
     ]
    }
   ],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount += 1\n",
    "    return doccount\n",
    "\n",
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / 1+df)\n",
    "\n",
    "my_idf_vector = [idf(word, corpusss) for word in vocabulary]\n",
    "\n",
    "\n",
    "print(my_idf_vector)\n",
    "print(len(my_idf_vector))\n",
    "print('\\n')\n",
    "\n",
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "print('length of vocab')\n",
    "print(len(list(vocabulary)))\n",
    "print('\\n')\n",
    "\n",
    "print('The inverse document frequency vector is [' + ', '.join(format(freq, 'f') for freq in my_idf_vector) + ']')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718  0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.69314718  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.69314718 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.69314718  0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.69314718  0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.69314718]]\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "def build_idf_matrix(idf_vector):\n",
    "    idf_mat = np.zeros((len(idf_vector), len(idf_vector)))\n",
    "    np.fill_diagonal(idf_mat, idf_vector)\n",
    "    return idf_mat\n",
    "\n",
    "my_idf_matrix = build_idf_matrix(my_idf_vector)\n",
    "\n",
    "print(my_idf_matrix)\n",
    "print(len(my_idf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9800', '38208', '2572', '38478', '13674', '28516', '2710', '21387', '36506', '25312', '28193', '40526', '43444', '24041', '3082', '13894', '44870', '30165', '2903', '2471', '3025', '18366', '744', '18318', '2718', '30267', '1259', '1838', '13247', '16972', '32528', '26416', '2913', '3015', '17231', '30081', '596', '17428', '1715', '713', '508', '16868', '13703', '16970', '33886', '1200', '1944', '35251', '9561', '16920', '32035', '3455', '40889', '3429', '1330', '3043', '29696', '10528', '24435', '16271', '18412', '46265', '612', '16276', '709', '10092', '25958', '24040', '8775', '13812', '28654', '1190', '11437', '3153', '1730', '44022', '25634'}\n",
      "[[0.095238095238095205, 0.42857142857142838, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.14285714285714279, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.19047619047619041, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603, 0.047619047619047603, 0.19047619047619041, 0.047619047619047603, 0.047619047619047603, 0.52380952380952361, 0.095238095238095205, 0.047619047619047603, 0.14285714285714279, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.14285714285714279, 0.095238095238095205, 0.047619047619047603, 0.14285714285714279, 0.3333333333333332, 0.047619047619047603, 0.047619047619047603, 0.238095238095238, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603, 0.047619047619047603, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603, 0.095238095238095205, 0.047619047619047603]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_term_matrix_tfidf = []\n",
    "\n",
    "for tf_vector in doc_term_matrix:\n",
    "    doc_term_matrix_tfidf.append(np.dot(tf_vector, my_idf_matrix))\n",
    "\n",
    "    \n",
    "doc_term_matrix_tfidf_l2 = []\n",
    "for tf_vector in doc_term_matrix_tfidf:\n",
    "    doc_term_matrix_tfidf_l2.append(l2_normalizer(tf_vector))\n",
    "    \n",
    "print(vocabulary)\n",
    "print(doc_term_matrix_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 63)\t0.238095238095\n",
      "  (0, 65)\t0.0952380952381\n",
      "  (0, 0)\t0.047619047619\n",
      "  (0, 31)\t0.047619047619\n",
      "  (0, 76)\t0.0952380952381\n",
      "  (0, 75)\t0.142857142857\n",
      "  (0, 60)\t0.428571428571\n",
      "  (0, 54)\t0.190476190476\n",
      "  (0, 46)\t0.52380952381\n",
      "  (0, 15)\t0.333333333333\n",
      "  (0, 12)\t0.047619047619\n",
      "  (0, 1)\t0.047619047619\n",
      "  (0, 39)\t0.047619047619\n",
      "  (0, 14)\t0.0952380952381\n",
      "  (0, 34)\t0.047619047619\n",
      "  (0, 2)\t0.047619047619\n",
      "  (0, 55)\t0.0952380952381\n",
      "  (0, 4)\t0.142857142857\n",
      "  (0, 10)\t0.0952380952381\n",
      "  (0, 19)\t0.0952380952381\n",
      "  (0, 52)\t0.0952380952381\n",
      "  (0, 37)\t0.047619047619\n",
      "  (0, 42)\t0.047619047619\n",
      "  (0, 17)\t0.047619047619\n",
      "  (0, 38)\t0.190476190476\n",
      "  :\t:\n",
      "  (0, 9)\t0.047619047619\n",
      "  (0, 32)\t0.047619047619\n",
      "  (0, 23)\t0.047619047619\n",
      "  (0, 11)\t0.047619047619\n",
      "  (0, 7)\t0.047619047619\n",
      "  (0, 22)\t0.047619047619\n",
      "  (0, 51)\t0.047619047619\n",
      "  (0, 49)\t0.047619047619\n",
      "  (0, 29)\t0.047619047619\n",
      "  (0, 50)\t0.047619047619\n",
      "  (0, 5)\t0.047619047619\n",
      "  (0, 62)\t0.047619047619\n",
      "  (0, 58)\t0.047619047619\n",
      "  (0, 13)\t0.047619047619\n",
      "  (0, 66)\t0.047619047619\n",
      "  (0, 44)\t0.047619047619\n",
      "  (0, 25)\t0.047619047619\n",
      "  (0, 28)\t0.047619047619\n",
      "  (0, 47)\t0.047619047619\n",
      "  (0, 35)\t0.047619047619\n",
      "  (0, 21)\t0.047619047619\n",
      "  (0, 20)\t0.047619047619\n",
      "  (0, 41)\t0.047619047619\n",
      "  (0, 3)\t0.047619047619\n",
      "  (0, 16)\t0.047619047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "tfidf_matrix_doc = tfidf_vectorizer.fit_transform(corpusss)\n",
    "\n",
    "print(tfidf_matrix_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2280 3068 457 26763 27631 14645 732 4332 2690 2923 20646 38527 27352 \\n612 \\n1407 2986 \\n25607 432 2148 3140 \\n27414 31424 7680 2280 3068 457 24554 30066 855 1715 11629 \\n26763 18571 27631 14645 732 4332 \\n28226 23520 27646 21192 3015 24310 23142 \\n2280 3068 457 1200 \\n596 855 3015 732 1715 2033 \\n27414 2345 2471 699 24310 43624 2878 32518 13629 17554 \\n17030 18380 9561 \\n31765 19448 31359 3012 18828 \\n27646 2345 21192 11738 3015 23600 \\n596 23600 21189 341 12133 3015 1259 18571 27631 3015 14645 \\n7680 2572 8994 2345 21892 3123 2855 \\n8250 32818 699 24310 7971 30165 9608 3015 23142 \\n2280 3068 457 1200 \\n27414 3015 14177 469 1259 732 3237 24583 14177 \\n34043 9079 24310 2938 13109 34474 \\n20818 3015 13629 34445 13910 \\n24310 1408 34770 379 28672 29978 3015 19217 \\n21478 16574 10340 28940 \\n24054 3015 32474 1906 739 34445 2737 \\n9242 2938 1259 10355 3015 15128 \\n1155 34179 13023 \\n8769 17442 2717 24783 14645 19486 \\n3025 3379 39506 \\n27414 2345 1728 34975 662 27647 25995 25944 7570 23390 24310 3015 7971 \\n1027 ']\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"Query\", \"*\"))\n",
    "\n",
    "query_corpus = []\n",
    "\n",
    "for file_path in file_list[0:1]:\n",
    "    with open(file_path) as f_input:\n",
    "        lines = f_input.read()\n",
    "        lines = re.sub('-1', '', lines)\n",
    "        lines = lines.strip('\\n')\n",
    "        query_corpus.append(lines)\n",
    "\n",
    "print(query_corpus)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('2280', 4), ('3068', 4), ('457', 4), ('26763', 2), ('27631', 3), ('14645', 4), ('732', 4), ('4332', 2), ('2690', 1), ('2923', 1), ('20646', 1), ('38527', 1), ('27352', 1), ('612', 1), ('1407', 1), ('2986', 1), ('25607', 1), ('432', 1), ('2148', 1), ('3140', 1), ('27414', 4), ('31424', 1), ('7680', 2), ('24554', 1), ('30066', 1), ('855', 2), ('1715', 2), ('11629', 1), ('18571', 2), ('28226', 1), ('23520', 1), ('27646', 2), ('21192', 2), ('3015', 12), ('24310', 6), ('23142', 2), ('1200', 2), ('596', 2), ('2033', 1), ('2345', 4), ('2471', 1), ('699', 2), ('43624', 1), ('2878', 1), ('32518', 1), ('13629', 2), ('17554', 1), ('17030', 1), ('18380', 1), ('9561', 1), ('31765', 1), ('19448', 1), ('31359', 1), ('3012', 1), ('18828', 1), ('11738', 1), ('23600', 2), ('21189', 1), ('341', 1), ('12133', 1), ('1259', 3), ('2572', 1), ('8994', 1), ('21892', 1), ('3123', 1), ('2855', 1), ('8250', 1), ('32818', 1), ('7971', 2), ('30165', 1), ('9608', 1), ('14177', 2), ('469', 1), ('3237', 1), ('24583', 1), ('34043', 1), ('9079', 1), ('2938', 2), ('13109', 1), ('34474', 1), ('20818', 1), ('34445', 2), ('13910', 1), ('1408', 1), ('34770', 1), ('379', 1), ('28672', 1), ('29978', 1), ('19217', 1), ('21478', 1), ('16574', 1), ('10340', 1), ('28940', 1), ('24054', 1), ('32474', 1), ('1906', 1), ('739', 1), ('2737', 1), ('9242', 1), ('10355', 1), ('15128', 1), ('1155', 1), ('34179', 1), ('13023', 1), ('8769', 1), ('17442', 1), ('2717', 1), ('24783', 1), ('19486', 1), ('3025', 1), ('3379', 1), ('39506', 1), ('1728', 1), ('34975', 1), ('662', 1), ('27647', 1), ('25995', 1), ('25944', 1), ('7570', 1), ('23390', 1), ('1027', 1)])\n"
     ]
    }
   ],
   "source": [
    "#here got error\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "for doc in query_corpus:\n",
    "    tf_query = Counter()\n",
    "    for word in re.split(' |\\\\n', doc):\n",
    "        tf_query[word] += 1\n",
    "    del tf_query['']\n",
    "    print(tf_query.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our query vocabulary vector is [9800, 38208, 2572, 38478, 13674, 28516, 2710, 21387, 36506, 25312, 28193, 40526, 43444, 24041, 3082, 13894, 44870, 30165, 2903, 2471, 3025, 18366, 744, 18318, 2718, 30267, 1259, 1838, 13247, 16972, 32528, 26416, 2913, 3015, 17231, 30081, 596, 17428, 1715, 713, 508, 16868, 13703, 16970, 33886, 1200, 1944, 35251, 9561, 16920, 32035, 3455, 40889, 3429, 1330, 3043, 29696, 10528, 24435, 16271, 18412, 46265, 612, 16276, 709, 10092, 25958, 24040, 8775, 13812, 28654, 1190, 11437, 3153, 1730, 44022, 25634]\n",
      "The query is 2280 3068 457 26763 27631 14645 732 4332 2690 2923 20646 38527 27352 \n",
      "612 \n",
      "1407 2986 \n",
      "25607 432 2148 3140 \n",
      "27414 31424 7680 2280 3068 457 24554 30066 855 1715 11629 \n",
      "26763 18571 27631 14645 732 4332 \n",
      "28226 23520 27646 21192 3015 24310 23142 \n",
      "2280 3068 457 1200 \n",
      "596 855 3015 732 1715 2033 \n",
      "27414 2345 2471 699 24310 43624 2878 32518 13629 17554 \n",
      "17030 18380 9561 \n",
      "31765 19448 31359 3012 18828 \n",
      "27646 2345 21192 11738 3015 23600 \n",
      "596 23600 21189 341 12133 3015 1259 18571 27631 3015 14645 \n",
      "7680 2572 8994 2345 21892 3123 2855 \n",
      "8250 32818 699 24310 7971 30165 9608 3015 23142 \n",
      "2280 3068 457 1200 \n",
      "27414 3015 14177 469 1259 732 3237 24583 14177 \n",
      "34043 9079 24310 2938 13109 34474 \n",
      "20818 3015 13629 34445 13910 \n",
      "24310 1408 34770 379 28672 29978 3015 19217 \n",
      "21478 16574 10340 28940 \n",
      "24054 3015 32474 1906 739 34445 2737 \n",
      "9242 2938 1259 10355 3015 15128 \n",
      "1155 34179 13023 \n",
      "8769 17442 2717 24783 14645 19486 \n",
      "3025 3379 39506 \n",
      "27414 2345 1728 34975 662 27647 25995 25944 7570 23390 24310 3015 7971 \n",
      "1027 \n",
      "the tf_query vector for Query 1 is [1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 2, 1, 4, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 4, 4, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
      "All Combined here is our master query term matrix: \n",
      "[[1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 2, 1, 4, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 12, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 4, 4, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_query = build_lexicon(query_corpus)\n",
    "\n",
    "doc_term_matrix_query = []\n",
    "print('Our query vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "\n",
    "for query in query_corpus:\n",
    "    print('The query is ' + query + '')\n",
    "    tf_query_vector = [tf(word, doc) for word in vocabulary_query]\n",
    "    tf_query_vector_string = ', '.join(format(freq, 'd')for freq in tf_query_vector)\n",
    "    print('the tf_query vector for Query %d is [%s]'%((query_corpus.index(query)+1), tf_query_vector_string))\n",
    "    doc_term_matrix_query.append(tf_query_vector)\n",
    "    \n",
    "print('All Combined here is our master query term matrix: ')\n",
    "print(doc_term_matrix_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old query term matrix: \n",
      "[[ 1  1  1  1  1  2  1  2  2  1  1  1  2  1  4  2  1  1  1  2  1  4  1  1\n",
      "   4  1  1  2  1  1  1  1  4  1  1  1  1  1  2  1  1  1  1  1  1  3  1  1\n",
      "   1  1  1  1  1  2  1  1  1  1  2  1  2  1  1  2  1  1  1  1  1  1  1  1\n",
      "   1  1  1  2 12  1  1  1  1  2  1  6  1  1  1  1  4  4  1  1  3  1  1  2\n",
      "   1  1  1  1  1  1  1  1  1  1  1  2  2  4  1  1  1  1  1  2  1  1  1  1\n",
      "   1]]\n",
      "\n",
      " A query term matrix with row-wise L2 norms of 1: \n",
      "[[0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.09186304243492507, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.18372608486985015, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.18372608486985015, 0.04593152121746254, 0.04593152121746254, 0.18372608486985015, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.18372608486985015, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.13779456365238762, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.5511782546095505, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.27558912730477525, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.18372608486985015, 0.18372608486985015, 0.04593152121746254, 0.04593152121746254, 0.13779456365238762, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.09186304243492507, 0.18372608486985015, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.09186304243492507, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254, 0.04593152121746254]]\n",
      "here is the length\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_term_matrix_query_l2 = []\n",
    "\n",
    "for vec in doc_term_matrix_query:\n",
    "    doc_term_matrix_query_l2.append(l2_normalizer(vec))\n",
    "    \n",
    "print('A regular old query term matrix: ')\n",
    "print(np.matrix(doc_term_matrix_query))\n",
    "print('\\n A query term matrix with row-wise L2 norms of 1: ')\n",
    "print(doc_term_matrix_query_l2)\n",
    "print('here is the length')\n",
    "print(len(doc_term_matrix_query_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 39)\t0.18372608487\n",
      "  (0, 78)\t0.18372608487\n",
      "  (0, 102)\t0.18372608487\n",
      "  (0, 55)\t0.0918630424349\n",
      "  (0, 61)\t0.137794563652\n",
      "  (0, 16)\t0.18372608487\n",
      "  (0, 108)\t0.18372608487\n",
      "  (0, 100)\t0.0918630424349\n",
      "  (0, 56)\t0.0459315212175\n",
      "  (0, 69)\t0.0459315212175\n",
      "  (0, 32)\t0.0459315212175\n",
      "  (0, 97)\t0.0459315212175\n",
      "  (0, 58)\t0.0459315212175\n",
      "  (0, 105)\t0.0459315212175\n",
      "  (0, 13)\t0.0459315212175\n",
      "  (0, 71)\t0.0459315212175\n",
      "  (0, 51)\t0.0459315212175\n",
      "  (0, 99)\t0.0459315212175\n",
      "  (0, 37)\t0.0459315212175\n",
      "  (0, 81)\t0.0459315212175\n",
      "  (0, 60)\t0.18372608487\n",
      "  (0, 82)\t0.0459315212175\n",
      "  (0, 111)\t0.0918630424349\n",
      "  (0, 47)\t0.0459315212175\n",
      "  (0, 73)\t0.0459315212175\n",
      "  :\t:\n",
      "  (0, 109)\t0.0459315212175\n",
      "  (0, 59)\t0.0459315212175\n",
      "  (0, 118)\t0.0459315212175\n",
      "  (0, 2)\t0.0459315212175\n",
      "  (0, 17)\t0.0459315212175\n",
      "  (0, 3)\t0.0459315212175\n",
      "  (0, 91)\t0.0459315212175\n",
      "  (0, 9)\t0.0459315212175\n",
      "  (0, 115)\t0.0459315212175\n",
      "  (0, 22)\t0.0459315212175\n",
      "  (0, 57)\t0.0459315212175\n",
      "  (0, 50)\t0.0459315212175\n",
      "  (0, 30)\t0.0459315212175\n",
      "  (0, 77)\t0.0459315212175\n",
      "  (0, 88)\t0.0459315212175\n",
      "  (0, 98)\t0.0459315212175\n",
      "  (0, 21)\t0.0459315212175\n",
      "  (0, 95)\t0.0459315212175\n",
      "  (0, 106)\t0.0459315212175\n",
      "  (0, 63)\t0.0459315212175\n",
      "  (0, 54)\t0.0459315212175\n",
      "  (0, 53)\t0.0459315212175\n",
      "  (0, 110)\t0.0459315212175\n",
      "  (0, 41)\t0.0459315212175\n",
      "  (0, 0)\t0.0459315212175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "tfidf_matrix_doc = tfidf_vectorizer.fit_transform(query_corpus)\n",
    "\n",
    "print(tfidf_matrix_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-90310692cd8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdoc_term_matrix_query_tfidf_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtf_query_vector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_term_matrix_query_tfidf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdoc_term_matrix_query_tfidf_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_query_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-70ae74deaa7a>\u001b[0m in \u001b[0;36ml2_normalizer\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0ml2_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_term_matrix_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-70ae74deaa7a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0ml2_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_term_matrix_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "doc_term_matrix_query_tfidf = []\n",
    "\n",
    "for tf_query_vector in doc_term_matrix_query:\n",
    "    doc_term_matrix_query_tfidf.append(np.dot(tf_query_vector, my_idf_matrix))\n",
    "    \n",
    "doc_term_matrix_query_tfidf_l2 = []\n",
    "for tf_query_vector in doc_term_matrix_query_tfidf:\n",
    "    doc_term_matrix_query_tfidf_l2.append(l2_normalizer(tf_query_vector))\n",
    "    \n",
    "print(vocabulary_query)\n",
    "print(np.matrix(doc_term_matrix_query_tfidf_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1)\n",
    "term_freq_matrix_query = count_vectorizer.fit_transform(query_corpus)\n",
    "print(\"Vocabulary_query:\", count_vectorizer.vocabulary_)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(term_freq_matrix_query)\n",
    "\n",
    "tf_idf_matrix_query = tfidf.transform(term_freq_matrix_query)\n",
    "print(tf_idf_matrix_query.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = sum(p*q for p,q in zip(vector1, vector2))\n",
    "    magnitude = math.sqrt(sum([val**2 for val in vector1])) * math.sqrt(sum([val**2 for val in vector2]))\n",
    "    if not magnitude:\n",
    "        return 0\n",
    "    return dot_product/magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1)\n",
    "term_freq_matrix_query = count_vectorizer.fit_transform(corpusss)\n",
    "print(\"Vocabulary:\", count_vectorizer.vocabulary_)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(term_freq_matrix_query)\n",
    "\n",
    "tf_idf_matrix = tfidf.transform(term_freq_matrix_query)\n",
    "print(tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(tf_idf_matrix_query, tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_idf_matrix_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_term_matrix_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
